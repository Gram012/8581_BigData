{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gram012/8581_BigData/blob/main/Copy_of_8581_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Make a copy of this notebook: File → \"Save a copy in Drive\" (Optional if doing solo stuff)\n",
        "\n",
        "-Connect to GPU runtime: Runtime → \"Change runtime type\" → \"T4 GPU\"\n",
        "\n",
        "  I'm not totally sure what Colab's limits on GPU usage are, but it might be a good idea to have only one member of your group connect to a GPU runtime, while the rest stay on CPU. Most of this notebook can be run without a GPU, and if one person runs out of GPU credits, another can swap in\n",
        "\n"
      ],
      "metadata": {
        "id": "I4QOrqytzuGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Mount Google Drive with code block below. You'll need to grant Google Drive some permissions for this to work"
      ],
      "metadata": {
        "id": "h0b4yJOxy5Wk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LU6XWmXD6W8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72481acc-7afb-4729-8086-d1995f0aa6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Open up the file explorer in the left sidebar (using the folder icon) and locate the zip file in your Drive. In the cell below, replace the path with the path to your file, and run the cell to unzip it."
      ],
      "metadata": {
        "id": "jmdmqHTvy39W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the path to your copy of the zip file\n",
        "# Should take ~8 minutes :( The %%capture is there to suppress output\n",
        "%%capture\n",
        "!unzip drive/MyDrive/8581_Project/PHYS8581_data.zip"
      ],
      "metadata": {
        "id": "nJg7Of8ey23Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixes a bug that comes up sometimes\n",
        "# If you get an error involving a \"UTF-8 encoding\", uncomment and run the below\n",
        "\n",
        "# import locale\n",
        "# locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "la5P0Fr3zMco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Run the cell below to do a little organization and clean-up (not needed right now)"
      ],
      "metadata": {
        "id": "cgGy-kd4zNrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For convenience, move everything into the top-level, and remove a file\n",
        "# that osx puts in zips\n",
        "#!mv PHYS8581_data/* /content/\n",
        "#!rm -r __MACOSX"
      ],
      "metadata": {
        "id": "S1PJAUWMzQp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports!"
      ],
      "metadata": {
        "id": "jdUAPP0v0DJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NKmk_H5o1nt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_waveforms = '/content/PHYS8581_data/waveforms.hdf5'\n",
        "\n",
        "\n",
        "with h5py.File(file_waveforms, 'r') as f:\n",
        "    print(list(f.keys()))\n",
        "    parameters = f['parameters']\n",
        "    print(\"Parameters:\", list(parameters.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu9jfG0X0Eze",
        "outputId": "82c110a0-e7dd-4aac-f354-6d022fbee0e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['parameters', 'waveforms']\n",
            "Parameters: ['a_1', 'a_2', 'dec', 'ifo_snrs', 'mass_1', 'mass_2', 'phase', 'phi_12', 'phi_jl', 'psi', 'ra', 'redshift', 'snr', 'theta_jn', 'tilt_1', 'tilt_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contents of the README.txt:\n",
        "\n",
        "The background data in this directory is real data from LIGO's third observing run, O3.\n",
        "\n",
        "\n",
        "Each file name contains the GPS time of the start of the segment, as well as the duration of the segment in seconds.\n",
        "\n",
        "\n",
        "The data is sampled at 2048 Hz.\n",
        "\n",
        "\n",
        "Each file contains two data channels, \"H1\" and \"L1\", corresponding to data from the Hanford and Livingston interferometers.\n",
        "\n",
        "\n",
        "The detectors are located on opposite sides of the United States, so the noise in the detectors should be uncorrelated.\n",
        "\n",
        "\n",
        "This means that it's entirely valid to slice samples from these files non-coincidentally for training/testing: you can take windows from H1 and L1 that are at different times.\n",
        "\n",
        "\n",
        "This is a good way to increase the effective size of your dataset.\n",
        "\n",
        "The waveforms.hdf5 file contains 10,000 simulated binary neutron star (BNS) waveforms.\n",
        "The specifics are as follows:\n",
        " - Waveform approximant: TaylorF2\n",
        " - Minimum frequency: 20 Hz\n",
        " - Reference frequency: 50 Hz\n",
        " - Sample rate: 2048 Hz\n",
        " - Waveform duration: 60 s\n",
        " - Highpass frequency: 20 Hz\n",
        " - Parameter distributions:\n",
        "    - Mass 1: Triangular(1, 2.5, 2.5)\n",
        "    - Mass 2: Uniform(1, Mass 1)\n",
        "    - Spins and spin angles: 0\n",
        "    - Sky location: Isotropic\n",
        "    - Redshift: Uniform in volume between 0 and 0.01 (~43 Mpc)\n",
        "\n",
        "The upper bound on redshift was chosen to roughly match the distance of GW170817, the one BNS signal that's been detected.\n",
        "\n",
        "\n",
        "As a consequence, almost all of the signals in the dataset are relatively loud and should be detectable.\n",
        "\n",
        "\n",
        "If this ends up being too simple of a problem, the waveform dataset can be regenerated using a higher maximum redshift.\n",
        "\n",
        "Note that these signals have not been added into background, meaning that you can add the same signal into different background segments to get different training examples."
      ],
      "metadata": {
        "id": "qLgodMOW3xjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting with injecting waveforms"
      ],
      "metadata": {
        "id": "SV8l0I-H29hK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lwxGYEQu275-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}